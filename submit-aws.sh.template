#!/bin/bash
#Script to submit as an Amazon AWS EMR step. Copy this file to aws-discount.sh and 
#edit variables accordingly.

#For this script to work, it is necessary to install and configure the AWS CLI.

#The first argument is the cluster ID. The remaining arguments will be passed to the Discount driver process.
CLUSTER=$1
shift

#Bucket to store discount jars and data files
BUCKET=s3://my-bucket/discount

#Copy jars and data files the first time only, after which the following lines can safely be commented out
aws s3 cp lib/fastdoop-1.0.0.jar $BUCKET
aws s3 cp DOCKS/res_10_20_4_0.txt $BUCKET/DOCKS
aws s3 cp DOCKS/res_10_50_4_0.txt $BUCKET/DOCKS
aws s3 cp target/scala-2.11/discount_2.11-1.0.0.jar $BUCKET

COMMAND=(--packages org.rogach:scallop_2.11:latest.integration --jars $BUCKET/fastdoop-1.0.0.jar --class discount.spark.Discount $BUCKET/discount_2.11-1.0.0.jar $*)
RUNNER_ARGS="spark-submit"
for PARAM in ${COMMAND[@]}
do
  RUNNER_ARGS="$RUNNER_ARGS,$PARAM"
done


aws emr add-steps --cluster $CLUSTER --steps Type=CUSTOM_JAR,Name=Discount,ActionOnFailure=CONTINUE,Jar=command-runner.jar,Args=\[$RUNNER_ARGS\]
